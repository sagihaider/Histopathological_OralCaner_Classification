{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIu0sBN3r53R+XIZCIIyOI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/Histopathological_OralCaner_Classification/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/ftmp4cvtmb-1.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPTeU0anFK4i",
        "outputId": "152adf0e-e769-4204-ca10-a2cf7e5960f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 21:52:18--  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/ftmp4cvtmb-1.zip\n",
            "Resolving md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)... 52.218.84.3\n",
            "Connecting to md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)|52.218.84.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3098632250 (2.9G) [application/octet-stream]\n",
            "Saving to: ‘ftmp4cvtmb-1.zip’\n",
            "\n",
            "ftmp4cvtmb-1.zip    100%[===================>]   2.89G  20.1MB/s    in 2m 29s  \n",
            "\n",
            "2021-12-29 21:54:47 (19.9 MB/s) - ‘ftmp4cvtmb-1.zip’ saved [3098632250/3098632250]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "os.rename('/content/ftmp4cvtmb-1.zip', '/content/data.zip')\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/data.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BTjaRc_GT9q",
        "outputId": "ae20b5b6-c8f9-441a-e49d-0d2a05f5a5ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/data_merged'\n",
        "if not os.path.exists(base_dir): os.mkdir(base_dir)\n",
        "\n",
        "normal_dir = os.path.join(base_dir, 'normal')\n",
        "os.mkdir(normal_dir)\n",
        "\n",
        "ocss_dir = os.path.join(base_dir, 'oscc')\n",
        "os.mkdir(ocss_dir)"
      ],
      "metadata": {
        "id": "q-shw5XgI-Kt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/First Set/100x Normal Oral Cavity Histopathological Images\"\n",
        "dst_dir = \"/content/data_merged/normal\"\n",
        "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
        "    shutil.copy(jpgfile, dst_dir)\n",
        "\n",
        "src_dir = \"/content/Second Set/400x Normal Oral Cavity Histopathological Images\"\n",
        "dst_dir = \"/content/data_merged/normal\"\n",
        "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
        "    shutil.copy(jpgfile, dst_dir)\n",
        "\n",
        "src_dir = \"/content/First Set/100x OSCC Histopathological Images\"\n",
        "dst_dir = \"/content/data_merged/oscc\"\n",
        "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
        "    shutil.copy(jpgfile, dst_dir)\n",
        "\n",
        "src_dir = \"/content/First Set/400x OSCC Histopathological Images\"\n",
        "dst_dir = \"/content/data_merged/oscc\"\n",
        "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
        "    shutil.copy(jpgfile, dst_dir)\n"
      ],
      "metadata": {
        "id": "BYy0qHPxI67s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training normal images:', len(os.listdir('/content/data_merged/normal/')))\n",
        "print('total training oscc images:', len(os.listdir('/content/data_merged/oscc/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ph0CdhrYXWF",
        "outputId": "78606f25-86b7-42f2-f38b-2f5d20fa138e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training oscc images: 290\n",
            "total training oscc images: 439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path='/content/data_merged/normal/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "  dst =\"normal\" + str(count) + \".jpg\"\n",
        "  src =path+ filename \n",
        "  dst =path+ dst \n",
        "  # rename() function will \n",
        "  # rename all the files \n",
        "  os.rename(src, dst)\n",
        "\n",
        "path='/content/data_merged/oscc/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "  dst =\"oscc\" + str(count) + \".jpg\"\n",
        "  src =path+ filename \n",
        "  dst =path+ dst \n",
        "  # rename() function will \n",
        "  # rename all the files \n",
        "  os.rename(src, dst)"
      ],
      "metadata": {
        "id": "OvEry8JJUiUc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate base directory\n",
        "shutil.rmtree('/content/CancerData')\n",
        "final_dir = '/content/CancerData'\n",
        "os.mkdir(final_dir)"
      ],
      "metadata": {
        "id": "lP75MpfbVQU_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "train_dir = os.path.join(final_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(final_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(final_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_normal_dir = os.path.join(train_dir, 'normal')\n",
        "os.mkdir(train_normal_dir)\n",
        "\n",
        "train_oscc_dir = os.path.join(train_dir, 'oscc')\n",
        "os.mkdir(train_oscc_dir)\n",
        "\n",
        "validation_normal_dir = os.path.join(validation_dir, 'normal')\n",
        "os.mkdir(validation_normal_dir)\n",
        "\n",
        "validation_oscc_dir = os.path.join(validation_dir, 'oscc')\n",
        "os.mkdir(validation_oscc_dir)\n",
        "\n",
        "test_normal_dir = os.path.join(test_dir, 'normal')\n",
        "os.mkdir(test_normal_dir)\n",
        "\n",
        "test_oscc_dir = os.path.join(test_dir, 'oscc')\n",
        "os.mkdir(test_oscc_dir)"
      ],
      "metadata": {
        "id": "5-zTdiVEVdHq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_dataset_dir_oscc = '/content/data_merged/oscc'\n",
        "original_dataset_dir_normal = '/content/data_merged/normal'\n",
        "\n",
        "import shutil\n",
        "fnames = ['oscc{}.jpg'.format(i) for i in range(307)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_oscc, fname)\n",
        "    dst = os.path.join(train_oscc_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['oscc{}.jpg'.format(i) for i in range(307, 373)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_oscc, fname)\n",
        "    dst = os.path.join(validation_oscc_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['oscc{}.jpg'.format(i) for i in range(373, 439)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_oscc, fname)\n",
        "    dst = os.path.join(test_oscc_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['normal{}.jpg'.format(i) for i in range(203)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_normal, fname)\n",
        "    dst = os.path.join(train_normal_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['normal{}.jpg'.format(i) for i in range(203, 246)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_normal, fname)\n",
        "    dst = os.path.join(validation_normal_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['normal{}.jpg'.format(i) for i in range(246, 290)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_normal, fname)\n",
        "    dst = os.path.join(test_normal_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "CCk9FYZUWP7b"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training oscc images:', len(os.listdir(train_oscc_dir)))\n",
        "print('total training normal images:', len(os.listdir(train_normal_dir)))\n",
        "\n",
        "print('total validation oscc images:', len(os.listdir(validation_oscc_dir)))\n",
        "print('total validation normal images:', len(os.listdir(validation_normal_dir)))\n",
        "\n",
        "print('total test oscc images:', len(os.listdir(test_oscc_dir)))\n",
        "print('total test normal images:', len(os.listdir(test_normal_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBfZ7BhaXvX_",
        "outputId": "42c76d3c-84ef-4ac5-84be-65819b3a52a7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training oscc images: 307\n",
            "total training normal images: 203\n",
            "total validation oscc images: 66\n",
            "total validation normal images: 43\n",
            "total test oscc images: 66\n",
            "total test normal images: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and Compile the Model\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='RMSprop',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzpMzUX7ZhQG",
        "outputId": "1ab8c6c1-f73e-4dfb-c42e-6869b1de3eac"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 74, 74, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 36, 36, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 17, 17, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddXsI1Y_a8xx",
        "outputId": "f1926802-3b30-4386-bc2c-9cf6a3ef7a62"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 510 images belonging to 2 classes.\n",
            "Found 109 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model \n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=10,\n",
        "                              epochs=10,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FvvM7NYbLa-",
        "outputId": "6ad90e56-139b-45e6-be2a-91e03cb92833"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6737 - acc: 0.6100WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.6737 - acc: 0.6100 - val_loss: 0.6760 - val_acc: 0.6055\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.6656 - acc: 0.6053\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.6825 - acc: 0.6000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.6746 - acc: 0.6000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 30s 3s/step - loss: 0.6939 - acc: 0.6100\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.6653 - acc: 0.6316\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.6836 - acc: 0.5579\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.6968 - acc: 0.6158\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.7892 - acc: 0.5850\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.6574 - acc: 0.5800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "9Cu-wQhNcdOy",
        "outputId": "75944a41-2c72-401f-d1d5-1532c228674e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-6bec3b3e31b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}