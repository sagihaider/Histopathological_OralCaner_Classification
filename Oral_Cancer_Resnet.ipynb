{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oral_Cancer_Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/Histopathological_OralCaner_Classification/blob/main/Oral_Cancer_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XQxvzm01g2NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58ba6be-4b6a-4ad8-f695-4e20f34d77e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/Colab Notebooks/Oral Cancer Classification/CancerData' # Sriramya Link\n",
        "base_dir = '/content/drive/MyDrive/Data/Oral Cancer Classification/CancerData'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "metadata": {
        "id": "wyDs5t2jg9o8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input, \n",
        "                           rotation_range=180,\n",
        "                           width_shift_range=0.1,\n",
        "                           height_shift_range=0.1,\n",
        "                           zoom_range=0.1,\n",
        "                           horizontal_flip=True,\n",
        "                           vertical_flip=True,\n",
        "                           fill_mode='nearest',\n",
        ")\n",
        "image_size = 224\n",
        "batch_size = 16\n",
        "\n",
        "print(\"\\nTrain Batches: \")\n",
        "train_batches = datagen.flow_from_directory(directory=train_dir,\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='binary',\n",
        "                                            shuffle=True)\n",
        "\n",
        "print(\"\\nTest Batches: \")\n",
        "test_batches =datagen.flow_from_directory(validation_dir,\n",
        "                                           target_size=(image_size,image_size),\n",
        "                                           batch_size=batch_size,                                         \n",
        "                                           class_mode='binary',\n",
        "                                           shuffle=False)"
      ],
      "metadata": {
        "id": "_YqvEsUGhFcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d17f939-a249-4ec1-af20-54fc9274a742"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Batches: \n",
            "Found 520 images belonging to 2 classes.\n",
            "\n",
            "Test Batches: \n",
            "Found 180 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Soft Attention\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "import tensorflow as tf\n",
        "\n",
        "class SoftAttention(Layer):\n",
        "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
        "        self.channels=int(ch)\n",
        "        self.multiheads = m\n",
        "        self.aggregate_channels = aggregate\n",
        "        self.concat_input_with_scaled = concat_with_x\n",
        "        super(SoftAttention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "\n",
        "        self.i_shape = input_shape\n",
        "\n",
        "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
        "    \n",
        "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "\n",
        "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
        "        else:\n",
        "            if self.concat_input_with_scaled:\n",
        "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
        "            else:\n",
        "                self.out_features_shape = input_shape\n",
        "        \n",
        "\n",
        "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
        "                                        initializer='he_uniform',\n",
        "                                        name='kernel_conv3d')\n",
        "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
        "                                      initializer='zeros',\n",
        "                                      name='bias_conv3d')\n",
        "\n",
        "        super(SoftAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        exp_x = K.expand_dims(x,axis=-1)\n",
        "\n",
        "        c3d = K.conv3d(exp_x,\n",
        "                     kernel=self.kernel_conv3d,\n",
        "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
        "        conv3d = K.bias_add(c3d,\n",
        "                        self.bias_conv3d)\n",
        "        conv3d = kl.Activation('relu')(conv3d)\n",
        "\n",
        "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
        "\n",
        "        \n",
        "        conv3d = K.squeeze(conv3d, axis=-1)\n",
        "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
        "\n",
        "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
        "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
        "\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
        "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
        "   \n",
        "            x_exp = K.expand_dims(x,axis=-2)\n",
        "   \n",
        "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
        "  \n",
        "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
        "\n",
        "        else:\n",
        "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
        "\n",
        "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
        "\n",
        "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
        "\n",
        "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
        "\n",
        "        if self.concat_input_with_scaled:\n",
        "            o = kl.Concatenate(axis=-1)([u,x])\n",
        "        else:\n",
        "            o = u\n",
        "        \n",
        "        return [o, softmax_alpha]\n",
        "\n",
        "    def compute_output_shape(self, input_shape): \n",
        "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "        return super(SoftAttention,self).get_config()\n",
        " "
      ],
      "metadata": {
        "id": "ZKaqNzSUl7Fc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "MainInput=Input(shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "oFx5IBjCm_2d"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Layer1"
      ],
      "metadata": {
        "id": "yNBrnnwsnrUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,GlobalAveragePooling2D,BatchNormalization,Dropout\n",
        "\n",
        "def convlayer1(input_value):\n",
        "  conv1=Conv2D(filters=64, kernel_size=(3,3), strides=(2,2),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  conv1=BatchNormalization()(conv1)\n",
        "  pool1=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "  return pool1"
      ],
      "metadata": {
        "id": "BKU90oFUnAma"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Layer2"
      ],
      "metadata": {
        "id": "-pthn78Fn04e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convlayer2(input_value):\n",
        "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  conv2=BatchNormalization()(conv2)\n",
        "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv2)\n",
        "  conv2=BatchNormalization()(conv2)\n",
        "\n",
        "  resnet=add([input_value,conv2])\n",
        "  resnet=Activation(\"relu\")(resnet)\n",
        "  return resnet"
      ],
      "metadata": {
        "id": "LezFWOjon35c"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Layer3"
      ],
      "metadata": {
        "id": "mGh96oNPoC4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convlayer3(input_value):\n",
        "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  conv3=BatchNormalization()(conv3)\n",
        "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv3)\n",
        "  conv3=BatchNormalization()(conv3)\n",
        "\n",
        "\n",
        "  skip=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  skip=BatchNormalization()(skip)\n",
        "\n",
        "  resnet=add([skip,conv3])\n",
        "  resnet=Activation(\"relu\")(resnet)\n",
        "  return resnet"
      ],
      "metadata": {
        "id": "gIBwxBsPn7QP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Layer4"
      ],
      "metadata": {
        "id": "iMDSInvboK9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convlayer4(input_value):\n",
        "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  conv4=BatchNormalization()(conv4)\n",
        "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv4)\n",
        "  conv4=BatchNormalization()(conv4)\n",
        "\n",
        "\n",
        "  skip=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  skip=BatchNormalization()(skip)\n",
        "\n",
        "  resnet=add([skip,conv4])\n",
        "  resnet=Activation(\"relu\")(resnet)\n",
        "  return resnet"
      ],
      "metadata": {
        "id": "nyupraARoL4F"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Layer5"
      ],
      "metadata": {
        "id": "_4ipFU8nocmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convlayer5(input_value):\n",
        "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  conv5=BatchNormalization()(conv5)\n",
        "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv5)\n",
        "  conv5=BatchNormalization()(conv5)\n",
        "\n",
        "\n",
        "  skip=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
        "  skip=BatchNormalization()(skip)\n",
        "\n",
        "  resnet=add([skip,conv5])\n",
        "  resnet=Activation(\"relu\")(resnet)\n",
        "  return resnet"
      ],
      "metadata": {
        "id": "5bLSyzHnodYE"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation\n",
        "\n",
        "Block 1"
      ],
      "metadata": {
        "id": "b0tenexfojop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block1=convlayer1(MainInput)"
      ],
      "metadata": {
        "id": "Vf-o5E23okXA"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2"
      ],
      "metadata": {
        "id": "kaAG5MNRpIAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block2=convlayer2(block1)\n",
        "for i in range(0,2):\n",
        "  block2=convlayer2(block2)"
      ],
      "metadata": {
        "id": "CmS01QE2onX_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 3"
      ],
      "metadata": {
        "id": "dzYrt2rApOsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block2)\n",
        "block3=convlayer3(maxpool)\n",
        "\n",
        "for i in range(0,3):\n",
        "  block3=convlayer3(block3)"
      ],
      "metadata": {
        "id": "bpRUx34MpNsK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Soft Attention Layer"
      ],
      "metadata": {
        "id": "yEq5wOPWpW2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer2,map2 = SoftAttention(aggregate=True,m=16,\n",
        "                                      concat_with_x=False,ch=int(block3.shape[-1]),\n",
        "                                      name='soft_attention')(block3)\n",
        "attention_layer2=MaxPooling2D(pool_size=(2,2), padding='same')(attention_layer2)\n",
        "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block3)\n",
        "\n",
        "concat2=concatenate([maxpool,attention_layer2])\n",
        "conv = Activation(\"relu\")(concat2)\n",
        "conv= Dropout(0.5)(conv)"
      ],
      "metadata": {
        "id": "qOlKEypApUn3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 4"
      ],
      "metadata": {
        "id": "rm2Dlu9Lpes3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block4=convlayer4(conv)\n",
        "for i in range(0,5):\n",
        "  block4=convlayer4(block4)"
      ],
      "metadata": {
        "id": "l6WzJg16phmq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 5"
      ],
      "metadata": {
        "id": "qMYgfyjSpnMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block4)\n",
        "block5=convlayer5(maxpool)\n",
        "for i in range(0,2):\n",
        "  block5=convlayer5(block5)"
      ],
      "metadata": {
        "id": "hDcNXHm7prmU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Layer"
      ],
      "metadata": {
        "id": "tSFP9PEUqjDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "output = GlobalAveragePooling2D()(block5)\n",
        "output = Dense(1, activation='softmax')(output)\n",
        "model = Model(inputs=MainInput, outputs=output)"
      ],
      "metadata": {
        "id": "_knBkN2oqlKG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHbVzEIeqlxI",
        "outputId": "91efeb41-1cd4-45aa-b7cb-2a594d5d2b72"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 112, 112, 64  1792        ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 112, 112, 64  256        ['conv2d_92[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 56, 56, 64)  0           ['batch_normalization_92[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 56, 56, 64)   36928       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 56, 56, 64)  256         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 56, 56, 64)   36928       ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 56, 56, 64)  256         ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 56, 56, 64)   0           ['max_pooling2d_10[0][0]',       \n",
            "                                                                  'batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 56, 56, 64)   0           ['add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 56, 56, 64)  256         ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 56, 56, 64)   36928       ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 56, 56, 64)  256         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 56, 56, 64)   0           ['activation_34[0][0]',          \n",
            "                                                                  'batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 56, 56, 64)   0           ['add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 56, 56, 64)  256         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 56, 56, 64)   36928       ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 56, 56, 64)  256         ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_34 (Add)                   (None, 56, 56, 64)   0           ['activation_35[0][0]',          \n",
            "                                                                  'batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 56, 56, 64)   0           ['add_34[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 28, 28, 64)  0           ['activation_36[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 28, 28, 128)  73856       ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 28, 28, 128)  512        ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 28, 28, 128)  73856       ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 28, 28, 128)  147584      ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 28, 28, 128)  512        ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 28, 28, 128)  512        ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_35 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_101[0][0]',\n",
            "                                                                  'batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 28, 28, 128)  0           ['add_35[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 28, 28, 128)  512        ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 28, 28, 128)  147584      ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 28, 28, 128)  512        ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 28, 28, 128)  512        ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_104[0][0]',\n",
            "                                                                  'batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 28, 28, 128)  0           ['add_36[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 28, 28, 128)  512        ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 28, 28, 128)  147584      ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 28, 28, 128)  512        ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 28, 28, 128)  512        ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_37 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_107[0][0]',\n",
            "                                                                  'batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 28, 28, 128)  0           ['add_37[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 28, 28, 128)  512        ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 28, 28, 128)  147584      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 28, 28, 128)  147584      ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 28, 28, 128)  512        ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 28, 28, 128)  512        ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_38 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_110[0][0]',\n",
            "                                                                  'batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 28, 28, 128)  0           ['add_38[0][0]']                 \n",
            "                                                                                                  \n",
            " soft_attention (SoftAttention)  [(None, 28, 28, 128  18448      ['activation_40[0][0]']          \n",
            "                                ),                                                                \n",
            "                                 (None, 16, 28, 28)                                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 14, 14, 128)  0          ['activation_40[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 14, 14, 128)  0          ['soft_attention[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 14, 14, 256)  0           ['max_pooling2d_13[0][0]',       \n",
            "                                                                  'max_pooling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 14, 14, 256)  0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 14, 14, 256)  0           ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 14, 14, 256)  590080      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 14, 14, 256)  1024       ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 14, 14, 256)  590080      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 14, 14, 256)  1024       ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 14, 14, 256)  1024       ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_39 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_113[0][0]',\n",
            "                                                                  'batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 14, 14, 256)  0           ['add_39[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 14, 14, 256)  1024       ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 14, 14, 256)  1024       ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 14, 14, 256)  1024       ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_40 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_116[0][0]',\n",
            "                                                                  'batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 14, 14, 256)  0           ['add_40[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 14, 14, 256)  1024       ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 14, 14, 256)  1024       ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 14, 14, 256)  1024       ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_41 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_119[0][0]',\n",
            "                                                                  'batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 14, 14, 256)  0           ['add_41[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 14, 14, 256)  1024       ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 14, 14, 256)  1024       ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 14, 14, 256)  1024       ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_42 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_122[0][0]',\n",
            "                                                                  'batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 14, 14, 256)  0           ['add_42[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 14, 14, 256)  1024       ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 14, 14, 256)  1024       ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 14, 14, 256)  1024       ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_43 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_125[0][0]',\n",
            "                                                                  'batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 14, 14, 256)  0           ['add_43[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 14, 14, 256)  1024       ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 14, 14, 256)  590080      ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 14, 14, 256)  1024       ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 14, 14, 256)  1024       ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_44 (Add)                   (None, 14, 14, 256)  0           ['batch_normalization_128[0][0]',\n",
            "                                                                  'batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 14, 14, 256)  0           ['add_44[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 7, 7, 256)   0           ['activation_47[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 7, 7, 512)    1180160     ['max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 7, 7, 512)   2048        ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 7, 7, 512)    1180160     ['max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 7, 7, 512)    2359808     ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 7, 7, 512)   2048        ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 7, 7, 512)   2048        ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_45 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_131[0][0]',\n",
            "                                                                  'batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 512)    0           ['add_45[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 7, 7, 512)   2048        ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 7, 7, 512)    2359808     ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 7, 7, 512)   2048        ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 7, 7, 512)   2048        ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_46 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_134[0][0]',\n",
            "                                                                  'batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 512)    0           ['add_46[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 7, 7, 512)   2048        ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 7, 7, 512)    2359808     ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 7, 7, 512)   2048        ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 7, 7, 512)   2048        ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_47 (Add)                   (None, 7, 7, 512)    0           ['batch_normalization_137[0][0]',\n",
            "                                                                  'batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 512)    0           ['add_47[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 512)         0           ['activation_50[0][0]']          \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            513         ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,411,089\n",
            "Trainable params: 31,388,689\n",
            "Non-trainable params: 22,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "opt1=tf.keras.optimizers.RMSprop(learning_rate=0.01,epsilon=0.1)\n",
        "model.compile(optimizer=opt1,\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['acc', 'AUC','Recall','Precision'])"
      ],
      "metadata": {
        "id": "oFxWJ12wq7PA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "checkpoint=  ModelCheckpoint(filepath = 'ResNet34+SA.hdf5',\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=True)"
      ],
      "metadata": {
        "id": "pVFVhNAItCJf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=65, min_delta=0.001)\n",
        "history = model.fit(train_batches,\n",
        "                    steps_per_epoch=20,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=8,\n",
        "                    callbacks=[checkpoint,Earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83xt-LEHtDDQ",
        "outputId": "942529b0-77a0-4e70-fd9b-fcf6d7fa1914"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 188s - loss: 1.1083 - acc: 0.6406 - auc: 0.5000 - recall: 1.0000 - precision: 0.6406 - val_loss: 3361668.5000 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 188s/epoch - 9s/step\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 63s - loss: 0.7822 - acc: 0.6282 - auc: 0.5000 - recall: 1.0000 - precision: 0.6282 - val_loss: 1603.6676 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 63s/epoch - 3s/step\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 50s - loss: 0.6208 - acc: 0.6314 - auc: 0.5000 - recall: 1.0000 - precision: 0.6314 - val_loss: 380.5361 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 50s/epoch - 2s/step\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 45s - loss: 0.6086 - acc: 0.6094 - auc: 0.5000 - recall: 1.0000 - precision: 0.6094 - val_loss: 78.5653 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 45s/epoch - 2s/step\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 44s - loss: 0.7851 - acc: 0.6094 - auc: 0.5000 - recall: 1.0000 - precision: 0.6094 - val_loss: 4.4069 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 44s/epoch - 2s/step\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 42s - loss: 0.7165 - acc: 0.6094 - auc: 0.5000 - recall: 1.0000 - precision: 0.6094 - val_loss: 6.9791 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 42s/epoch - 2s/step\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 40s - loss: 0.6993 - acc: 0.6122 - auc: 0.5000 - recall: 1.0000 - precision: 0.6122 - val_loss: 22.4647 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 40s/epoch - 2s/step\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 41s - loss: 0.6886 - acc: 0.6058 - auc: 0.5000 - recall: 1.0000 - precision: 0.6058 - val_loss: 5.3699 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 41s/epoch - 2s/step\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 42s - loss: 0.6204 - acc: 0.6125 - auc: 0.5000 - recall: 1.0000 - precision: 0.6125 - val_loss: 20.2024 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 42s/epoch - 2s/step\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "20/20 - 42s - loss: 0.5344 - acc: 0.6156 - auc: 0.5000 - recall: 1.0000 - precision: 0.6156 - val_loss: 1.7517 - val_acc: 0.3750 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.3750 - 42s/epoch - 2s/step\n"
          ]
        }
      ]
    }
  ]
}